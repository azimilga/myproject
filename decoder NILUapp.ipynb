{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d77TXzrZZb7d"
   },
   "source": [
    "**WRITER'S IDENTITY**\n",
    "- AZIMIL GANI ALAM\n",
    "- Ph.D Student\n",
    "- Dept. Energy & Process Tech - NTNU\n",
    "\n",
    "\n",
    "**NOTE :**\n",
    "- This Python File runs in GoogleColab\n",
    "- This work uses **NILU - IS Data : Questionnaire Results**\n",
    "- we want to filterize data results from CSV models become process-ready for Machine Learning process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m9qQJqQ5X1Rm"
   },
   "source": [
    "**RULES**\n",
    "1. Run Library Import\n",
    "2. Run 'Default of Names\n",
    "3. Expand Schools Tab\n",
    "    - Run Identity\n",
    "    - Run Data Caller\n",
    "    - Run K\n",
    "4. Expand Classrooms\n",
    "    - Run Klasseroms one by one.\n",
    "\n",
    "to check the data cleaning result, run 'reviewer'. there is no cyclic command.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mut4f2nkycvj"
   },
   "source": [
    "# **Library Import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1019,
     "status": "ok",
     "timestamp": 1698601225330,
     "user": {
      "displayName": "Azimil Alam",
      "userId": "11823504813412490778"
     },
     "user_tz": -60
    },
    "id": "fjhmov-c_PhT"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5k8zB7YMWQH2"
   },
   "source": [
    "# Default  Names & Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Folder naming directory\n",
    "platform_directory = 'G:/My Drive/Colab Notebooks'   #Computer NILU\n",
    "platform_directory = 'C:/Users/azimilga/My Drive/Colab Notebooks'   #laptop NTNU\n",
    "\n",
    "folder_raw = 'data-raw'\n",
    "folder_ready = 'data-ready'\n",
    "\n",
    "folder_project = 'project'\n",
    "folder_export = 'export'\n",
    "folder_is = 'niluapp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1698601226313,
     "user": {
      "displayName": "Azimil Alam",
      "userId": "11823504813412490778"
     },
     "user_tz": -60
    },
    "id": "aBd2ro3cy7vq"
   },
   "outputs": [],
   "source": [
    "col_header = ['title', 'sessionid', 'date', 'time' ]\n",
    "response_counting = ['responses']\n",
    "is_col_main  = ['feel_air','feel_temp','feel_bright','feel_health','feel_noise']\n",
    "is_col_air   = ['air_smell','air_heavy','air_dry','air_dust','air_electshock']\n",
    "is_col_temp  = ['temp_coldhot','temp_draw','temp_coldfloor','temp_heatsun','temp_heater' ]\n",
    "is_col_light = ['bright_sun','bright_lamp_hi','bright_lamp_low']\n",
    "is_col_feel  = ['health_head','health_cough','health_tired','health_dryskin']\n",
    "columns_formation   = col_header + is_col_main + is_col_air + is_col_temp + is_col_light + is_col_feel\n",
    "\n",
    "school_col_name   = 'school_id'\n",
    "room_col_name     = 'room_id'\n",
    "date_name         = 'date'\n",
    "time_name         = 'time'\n",
    "manuf_col_name    = 'manuf_id'\n",
    "instr_col_name    = 'instr_id'\n",
    "serial_col_name   = 'serial_id'\n",
    "\n",
    "#Give a name for new column in purpose to count how many response / hour or response / day\n",
    "response_counting = 'responses'\n",
    "\n",
    "all_columns_set = {'HVORDAN ER FORMEN DIN NÅ?' : 'feel_health', \n",
    "                   'LUFTEN I ROMMET NÅ': 'feel_air', \n",
    "                   'LYS I ROMMET NÅ': 'feel_bright',\n",
    "                   'STØY I ROMMET NÅ' : 'feel_noise',\n",
    "                   'TEMPERATUR I ROMMET NÅ': 'feel_temp',\n",
    "                   \n",
    "                   'VOND LUKT' : 'air_smell' , \n",
    "                   'DÅRLIG TUNG/LUFT' : 'air_heavy', \n",
    "                #    'DÅRLIG/TUNG LUFT' : 'air_heavy',\n",
    "                   'TØRR LUFT' : 'air_dry', \n",
    "                   'STØV OG SKITT' : 'air_dust',\n",
    "                   'ELEKTRISK STØT' : 'air_electshock',\n",
    "                   \n",
    "                   'KALDT ELLER VARMT' : 'temp_coldhot',\n",
    "                   'TREKK KALD LUFT' : 'temp_draw',\n",
    "                   'FOR KALDT PÅ GULVET' : 'temp_coldfloor',\n",
    "                   'FOR MYE VARME FRA SOLSKINN' : 'temp_heatsun',\n",
    "                   'FOR MYE VARME FRA OVNER' : 'temp_heater' ,\n",
    "                   \n",
    "                   'SKARPT LYS FRA SOLA' : 'bright_sun',\n",
    "                   'SKARPT LYS TAKLAMPER' : 'bright_lamp_hi', \n",
    "                   'SVAKT LYS TAKLAMPER' : 'bright_lamp_low',\n",
    "                   \n",
    "                   'HODEPINE' : 'health_head',\n",
    "                   'HOSTE/SNØRRETE' : 'health_cough',\n",
    "                   'TRØTT/UKONSENTRERT' : 'health_tired',\n",
    "                   'TØRRE ØYNE/HENDER' : 'health_dryskin'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1698601226619,
     "user": {
      "displayName": "Azimil Alam",
      "userId": "11823504813412490778"
     },
     "user_tz": -60
    },
    "id": "A2zIqDgVmqZM"
   },
   "outputs": [],
   "source": [
    "#filtering rows data regarding to desired specific time\n",
    "start_time = '00:00:00'\n",
    "end_time   = '23:59:59'\n",
    "spec_date  = pd.to_datetime('today').strftime(\"%Y-%m-%d\")\n",
    "#name_date = pd.to_datetime('today').strftime(\"%y%m%d\")\n",
    "date_format_show =  '%Y-%m-%d'\n",
    "time_format_show =  '%H:%M'\n",
    "\n",
    "#filtering rows data regarding to desired specific time. We neglect data if there is a student did not answer anything. for example, from 808 responses, become 757 responses.\n",
    "min = 0\n",
    "\n",
    "def fill_temp_coldhot(row):\n",
    "    if pd.isna(row['temp_coldhot']):\n",
    "        if row['feel_temp'] <= 2:\n",
    "            return 0\n",
    "        else:\n",
    "            return row['temp_coldhot']  # Keep NaN if feel_temp > 2\n",
    "    else:\n",
    "        return row['temp_coldhot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCHOOL IDENTITY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bratteberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Classroom 141, 142, 210, Øst Brakker\n",
    "folder_year = '2023'\n",
    "start_date =  '2023-03-08'\n",
    "end_date   =  '2023-04-26'\n",
    "\n",
    "# Classroom 141, 210, Øst Brakker\n",
    "# folder_year = '2024'\n",
    "# start_date = '2024-02-26'\n",
    "# end_date  =  '2024-04-30'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "school_name = 'bratteberg'\n",
    "manuf_id    = 'niluapp'\n",
    "input_file_directory    = platform_directory + '/' + folder_project + '/' + folder_raw   + '/' + folder_year + '/' + school_name + '/' + manuf_id + '/'\n",
    "export_file_directory   = platform_directory + '/' + folder_project + '/' + folder_ready + '/' + folder_year + '/' + school_name + '/' + manuf_id + '/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Øyra Identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # classroom at 302 and 303\n",
    "# folder_year = '2023'\n",
    "# start_date  = '2023-03-13'\n",
    "# end_date    = '2023-04-18'\n",
    "\n",
    "# classroom at 303\n",
    "folder_year = '2024'\n",
    "start_date  = '2024-04-03'\n",
    "end_date    = '2024-04-18'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "school_name = 'øyra'\n",
    "manuf_id    = 'niluapp'\n",
    "input_file_directory    = platform_directory + '/' + folder_project + '/' + folder_raw   + '/' + folder_year + '/' + school_name + '/' + manuf_id + '/'\n",
    "export_file_directory   = platform_directory + '/' + folder_project + '/' + folder_ready + '/' + folder_year + '/' + school_name + '/' + manuf_id + '/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bikuben Identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classroom at B2708 ,  B3708\n",
    "folder_year = '2023'\n",
    "start_date  = '2023-03-13'\n",
    "end_date    = '2023-04-30'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "school_name = 'KubenVGS'\n",
    "manuf_id    = 'niluapp'\n",
    "input_file_directory    = platform_directory + '/' + folder_project + '/' + folder_raw   + '/' + folder_year + '/' + school_name + '/' + manuf_id + '/'\n",
    "export_file_directory   = platform_directory + '/' + folder_project + '/' + folder_ready + '/' + folder_year + '/' + school_name + '/' + manuf_id + '/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brannfjell Identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # classroom 23 and 27\n",
    "# folder_year = '2023'\n",
    "# start_date =  '2023-03-08'\n",
    "# end_date   =  '2023-04-26'\n",
    "\n",
    "# classroom 11 dan 23 and 27\n",
    "# folder_year = '2023'\n",
    "# start_date =  '2023-11-11'\n",
    "# end_date   =  '2023-11-28'\n",
    "\n",
    "# classroom 23 and 27\n",
    "# folder_year = '2024'\n",
    "# start_date = '2024-02-26'\n",
    "# end_date   =  '2024-03-08'\n",
    "\n",
    "# # classroom 11 dan 23 and 27\n",
    "folder_year = '2024'\n",
    "start_date = '2024-04-14'\n",
    "end_date   =  '2024-04-30'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "school_name = 'brannfjell'\n",
    "manuf_id    = 'niluapp'\n",
    "input_file_directory    = platform_directory + '/' + folder_project + '/' + folder_raw   + '/' + folder_year + '/' + school_name + '/' + manuf_id + '/'\n",
    "export_file_directory   = platform_directory + '/' + folder_project + '/' + folder_ready + '/' + folder_year + '/' + school_name + '/' + manuf_id + '/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Data Caller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path1 = input_file_directory # replace with the folder path\n",
    "csv_files1 = [f for f in os.listdir(folder_path1) if f.endswith('.txt') or f.endswith('19.csv')] # get list of csv files\n",
    "dfs1 = [] # list to store dataframes\n",
    "\n",
    "for file in csv_files1:\n",
    "    file_path = os.path.join(folder_path1, file) # get full path of csv file\n",
    "    df = pd.read_csv(file_path, ) # read csv file into a dataframe\n",
    "    dfs1.append(df) # append dataframe to list\n",
    "\n",
    "# concatenate dataframes in the list into a single dataframe\n",
    "DF1 = pd.concat(dfs1, ignore_index=True).rename(columns=all_columns_set)\n",
    "DF1.set_index('sessionid', inplace=True)\n",
    "\n",
    "# DF_air = DF1[DF1['text'].str.contains(r'^LUFTEN', case=True, na=False)].drop((is_col_light+is_col_temp+is_col_feel+['questionid']), axis=1).rename(columns={'numericvalue' : 'feel_air'})[is_col_air + ['feel_air']].astype(str).replace({'False': 0, 'True': 1}).astype(float)\n",
    "# DF_temp = DF1[DF1['text'].str.contains(r'^TEMPERATUR', case=True, na=False)].drop((is_col_light+is_col_air+is_col_feel), axis=1).rename(columns={'numericvalue' : 'feel_temp'})[is_col_temp + ['feel_temp']].astype(str).replace({'False': 0, 'True': 1}).astype(float)\n",
    "# DF_health = DF1[DF1['text'].str.contains(r'^HVORDAN', case=True, na=False)].drop((is_col_light+is_col_air+is_col_temp), axis=1).rename(columns={'numericvalue' : 'feel_health'})[is_col_feel + ['feel_health']].astype(str).replace({'False': 0, 'True': 1}).astype(float)\n",
    "# DF_light = DF1[DF1['text'].str.contains(r'^LYS', case=True, na=False)].drop((is_col_feel+is_col_air+is_col_temp), axis=1).rename(columns={'numericvalue' : 'feel_bright'})[is_col_light + ['feel_bright']].astype(str).replace({'False': 0, 'True': 1}).astype(float)\n",
    "# DF_noise = DF1[DF1['text'].str.contains(r'^STØY', case=True, na=False)].drop((is_col_feel+is_col_air+is_col_temp+is_col_light), axis=1).rename(columns={'numericvalue' : 'feel_noise'})[['feel_noise']].astype(float)\n",
    "\n",
    "DF_air = DF1[DF1['text'].str.contains(r'^LUFTEN', case=True, na=False)].rename(columns={'numericvalue' : 'feel_air'})[is_col_air + ['feel_air']].astype(str).replace({'False': 0, 'True': 1}).astype(float)\n",
    "DF_temp = DF1[DF1['text'].str.contains(r'^TEMPERATUR', case=True, na=False)].rename(columns={'numericvalue' : 'feel_temp'})[is_col_temp + ['feel_temp']].astype(str).replace({'False': 0, 'True': 1}).astype(float)\n",
    "DF_health = DF1[DF1['text'].str.contains(r'^HVORDAN', case=True, na=False)].rename(columns={'numericvalue' : 'feel_health'})[is_col_feel + ['feel_health']].astype(str).replace({'False': 0, 'True': 1}).astype(float)\n",
    "DF_light = DF1[DF1['text'].str.contains(r'^LYS', case=True, na=False)].rename(columns={'numericvalue' : 'feel_bright'})[is_col_light + ['feel_bright']].astype(str).replace({'False': 0, 'True': 1}).astype(float)\n",
    "DF_noise = DF1[DF1['text'].str.contains(r'^STØY', case=True, na=False)].rename(columns={'numericvalue' : 'feel_noise'})[['feel_noise']].astype(float)\n",
    "\n",
    "DF1['timestart'] = pd.to_datetime(DF1['timestart'])\n",
    "DF1['timeend'] = pd.to_datetime(DF1['timeend'])\n",
    "DF1['response_duration'] = (DF1['timeend'] - DF1['timestart']).dt.total_seconds()\n",
    "\n",
    "datechange = pd.to_datetime(DF1['timestart'])\n",
    "DF1['date'] = datechange.dt.strftime('%Y-%m-%d')\n",
    "DF1['time'] = datechange.dt.strftime('%H:%M')\n",
    "\n",
    "# Define the timezones (wrong time, and Europe/Oslo)\n",
    "IS_timezone = pytz.timezone('Africa/Luanda')  #why africa? time recording in IS Data is little bit wrong. it has 1 hour delatation but it doesnt consider DST principle. so, applying Africa Luanda, is a trick of that\n",
    "gmt_timezone = pytz.timezone('Europe/London')\n",
    "oslo_timezone = pytz.timezone('Europe/Oslo')\n",
    "\n",
    "# Adjust the datetime to the Oslo timezone and account for daylight saving time\n",
    "daylight_save_convert = datechange.dt.tz_localize(IS_timezone).dt.tz_convert(gmt_timezone)\n",
    "\n",
    "# Extract the adjusted time\n",
    "DF1['time'] = daylight_save_convert.dt.strftime('%H:%M')\n",
    "\n",
    "\n",
    "DF_head = DF1[DF1['text'].str.contains(r'^LUFTEN', case=True, na=False)][['title'\t,\t'time', 'date'\t  ,'response_duration'\t]]\n",
    "\n",
    "DF1_new = DF_head.join(DF_air).join(DF_temp).join(DF_health).join(DF_light).join(DF_noise)#.dropna(subset=is_col_main)\n",
    "DF1_new.head(4)\n",
    "print(DF_air.info())\n",
    "print(DF_temp.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace_correction = {7:4 , 6:3, 5:2, 4:1, 3:2, 2:3, 1:4  }\n",
    "# DF1_new['temp_coldhot'] = DF1_new['feel_temp'].copy()\n",
    "# DF1_new['feel_temp'] = DF1_new['feel_temp'].replace(replace_correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF1_new['temp_coldhot'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF1_new[is_col_main].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classroom School"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bratteberg Classrooms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1KsyONrnr9G7"
   },
   "source": [
    "### Klasserom 141"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1698601398996,
     "user": {
      "displayName": "Azimil Alam",
      "userId": "11823504813412490778"
     },
     "user_tz": -60
    },
    "id": "OkQoI_taB3I_"
   },
   "outputs": [],
   "source": [
    "room_id = 141\n",
    "class_dir = '141'\n",
    "is_data_class_name = 'Bratteberg klasserom '+class_dir\n",
    "instr_id = 'is_data'\n",
    "serial_id = 'noserial'\n",
    "file_name = instr_id+'-latest.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kl_-W66KsCFt"
   },
   "source": [
    "### Klasserom 142"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1698601401595,
     "user": {
      "displayName": "Azimil Alam",
      "userId": "11823504813412490778"
     },
     "user_tz": -60
    },
    "id": "36oVwboicD0f"
   },
   "outputs": [],
   "source": [
    "room_id = 142\n",
    "class_dir = '142'\n",
    "is_data_class_name = 'Bratteberg klasserom '+class_dir\n",
    "instr_id = 'is_data'\n",
    "serial_id = 'noserial'\n",
    "file_name = instr_id+'-latest.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ILew736csFgk"
   },
   "source": [
    "### Klasserom 210"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1698601402417,
     "user": {
      "displayName": "Azimil Alam",
      "userId": "11823504813412490778"
     },
     "user_tz": -60
    },
    "id": "Xnk0n2QvN72c"
   },
   "outputs": [],
   "source": [
    "room_id = 210\n",
    "class_dir = '210'\n",
    "is_data_class_name = 'Bratteberg klasserom '+class_dir\n",
    "instr_id = 'is_data'\n",
    "serial_id = 'noserial'\n",
    "file_name = instr_id+'-latest.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MB6m2Me8tId2"
   },
   "source": [
    "### Klasserom Øst Brakker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1698601403461,
     "user": {
      "displayName": "Azimil Alam",
      "userId": "11823504813412490778"
     },
     "user_tz": -60
    },
    "id": "dIDIlL5MtId9"
   },
   "outputs": [],
   "source": [
    "room_id = 'Øst brakker'\n",
    "class_dir = 'Øst brakker'\n",
    "is_data_class_name = 'Bratteberg Klasserom '+class_dir\n",
    "instr_id = 'is_data'\n",
    "serial_id = 'noserial'\n",
    "file_name = instr_id+'-latest.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tztyAnS-TKoh"
   },
   "source": [
    "## Øyra Classrooms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8W9NhFfTKoh"
   },
   "source": [
    "### Klasserom 302"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1698601411853,
     "user": {
      "displayName": "Azimil Alam",
      "userId": "11823504813412490778"
     },
     "user_tz": -60
    },
    "id": "UDb-TpdCTKoh"
   },
   "outputs": [],
   "source": [
    "room_id = 302\n",
    "class_dir = '302'\n",
    "is_data_class_name = 'Øyra klasserom 302-7b'\n",
    "instr_id = 'is_data'\n",
    "serial_id = 'noserial'\n",
    "file_name = instr_id+'-latest.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kfOZkT6-TKoi"
   },
   "source": [
    "### Klasserom 303"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1698601413112,
     "user": {
      "displayName": "Azimil Alam",
      "userId": "11823504813412490778"
     },
     "user_tz": -60
    },
    "id": "89EgIyc5TKoi"
   },
   "outputs": [],
   "source": [
    "room_id = 303\n",
    "class_dir = '303'\n",
    "is_data_class_name = 'Øyra klasserom 303'\n",
    "# is_data_class_name = [f for f in os.listdir() if f.startswith('Øyra klasserom 303') ]\n",
    "instr_id = 'is_data'\n",
    "serial_id = 'noserial'\n",
    "file_name = instr_id+'-latest.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C24yDYhCTKoi"
   },
   "source": [
    "### Klasserom 339"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DLX4PockTKoi"
   },
   "outputs": [],
   "source": [
    "room_id = 339\n",
    "class_dir = '339'\n",
    "is_data_class_name = 'Bratteberg klasserom '+class_dir\n",
    "instr_id = 'is_data'\n",
    "serial_id = 'noserial'\n",
    "file_name = instr_id+'-latest.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9WHXi2-TqZO7"
   },
   "source": [
    "## Brannfjell Classrooms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Klasserom 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "room_id = 11\n",
    "class_dir = '11'\n",
    "is_data_class_name = 'Brannfjell Rom ' + class_dir\n",
    "instr_id = 'is_data'\n",
    "serial_id = 'noserial'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "600OeP3EqZO7"
   },
   "source": [
    "### Klasserom 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1698601446845,
     "user": {
      "displayName": "Azimil Alam",
      "userId": "11823504813412490778"
     },
     "user_tz": -60
    },
    "id": "tXG8-WvAqZO7"
   },
   "outputs": [],
   "source": [
    "room_id = 23\n",
    "class_dir = '23'\n",
    "is_data_class_name = 'Brannfjell Rom ' + class_dir\n",
    "instr_id = 'is_data'\n",
    "serial_id = 'noserial'\n",
    "file_name = instr_id+'-latest.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0r80TIdNqZO7"
   },
   "source": [
    "### Klasserom 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1698601448473,
     "user": {
      "displayName": "Azimil Alam",
      "userId": "11823504813412490778"
     },
     "user_tz": -60
    },
    "id": "jlCqykI5qZO7"
   },
   "outputs": [],
   "source": [
    "room_id = 27\n",
    "class_dir = '27'\n",
    "is_data_class_name = 'Brannfjell Rom ' + class_dir\n",
    "instr_id = 'is_data'\n",
    "serial_id = 'noserial'\n",
    "file_name = instr_id+'-latest.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ufBDEuvCqZO8"
   },
   "source": [
    "### Klasserom 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 284,
     "status": "ok",
     "timestamp": 1698601454113,
     "user": {
      "displayName": "Azimil Alam",
      "userId": "11823504813412490778"
     },
     "user_tz": -60
    },
    "id": "rmWQjg5KqZO8"
   },
   "outputs": [],
   "source": [
    "room_id = 31\n",
    "class_dir = '31'\n",
    "is_data_class_name = 'Brannfjell Rom ' + class_dir\n",
    "instr_id = 'is_data'\n",
    "serial_id = 'noserial'\n",
    "file_name = instr_id+'-latest.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KubenVGS Classrooms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Klasserom B2708"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "room_id = 2708\n",
    "class_dir = 'B2708'\n",
    "is_data_class_name = 'Bikuben B2708'\n",
    "instr_id = 'is_data'\n",
    "serial_id = 'noserial'\n",
    "file_name = instr_id+'-latest.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Klasserom B3708"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "room_id = 3708\n",
    "class_dir = 'B3708'\n",
    "is_data_class_name = 'Bikuben B3708'\n",
    "# is_data_class_name = [f for f in os.listdir() if f.startswith('Øyra klasserom 303') ]\n",
    "instr_id = 'is_data'\n",
    "serial_id = 'noserial'\n",
    "file_name = instr_id+'-latest.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing & Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF2 = DF1_new[DF1_new['title'].str.contains(class_dir)].reset_index()\n",
    "\n",
    "DF2 [school_col_name]  = school_name\n",
    "DF2 [room_col_name]    = class_dir\n",
    "DF2 [manuf_col_name]   = manuf_id\n",
    "DF2 [instr_col_name]   = instr_id\n",
    "DF2 [serial_col_name]  = serial_id\n",
    "\n",
    "cols_to_move = [school_col_name, room_col_name,'date', 'time', manuf_col_name, instr_col_name, serial_col_name, 'sessionid']+is_col_main\n",
    "DF2         = DF2[ cols_to_move + [ col for col in DF2.columns if col not in cols_to_move ] ].drop([ 'title'], axis=1)\n",
    "#DF2['time'].unique()\n",
    "\n",
    "#filtering rows data regarding to desired specific time. We neglect data if there is a student did not answer anything. for example, from 808 responses, become 757 responses.\n",
    "min = 0\n",
    "\n",
    "#we filterize table with new name of DataFrame, and use specific date and time intervals like above. index has been reset as well.\n",
    "#his tends to eliminate \"Lazy students\" who dont answers all main questions at once. they were considered as outliers.\n",
    "DF2_listed = DF2 [(DF2['feel_air'] > min) | (DF2['feel_temp']> min) | (DF2['feel_bright']> min) | (DF2['feel_health'] > min) | (DF2['feel_noise'] > min)].reset_index(level=0, drop=True)\n",
    "\n",
    "\n",
    "#activate this command if we want to select specified date / today's date\n",
    "#DF2_listed = DF2_listed[DF2_listed['date']==spec_date]\n",
    "DF2_listed  = DF2_listed[DF2_listed['date'].between(start_date,end_date)]\n",
    "    \n",
    "# DF2_listed['temp_coldhot'] = DF2_listed['feel_temp'].copy()    #Special only for Brannfjell 2024 (room 23 )\n",
    "# replace_dict2 = {1:4, 7:4, 6:3, 2:3, 5:2, 3:2, 4:1}             #Special only for Brannfjell 2024 (room 23 )\n",
    "# DF2_listed['feel_temp'] = DF2_listed['feel_temp'] .replace(replace_dict2)    #Special only for Brannfjell 2024 (room 23 )\n",
    "\n",
    "# DF2_listed['temp_coldhot'] = DF2_listed.apply(fill_temp_coldhot, axis=1)   \n",
    "\n",
    "#put spesific Directory and File Name.\n",
    "name_time = datetime.strptime((DF2_listed[time_name].iloc[0]),'%H:%M').strftime('%H%M')\n",
    "name_date = datetime.strptime((DF2_listed[date_name].iloc[0]),'%Y-%m-%d').strftime('%Y%m%d')\n",
    "\n",
    "directory_path = export_file_directory +class_dir+'/'\n",
    "filename       = school_name+'_'+class_dir+ '_'+ instr_id + '_'+serial_id +'_'+name_date +'_'+ name_time + '.csv'\n",
    "\n",
    "\n",
    "\n",
    "# save dataframe (accumulative format) to CSV file in specified directory\n",
    "DF2_listed.to_csv(directory_path + filename, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(directory_path + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF2_listed [ is_col_temp + ['feel_temp'] ].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF2_listed [ is_col_air + ['feel_air']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF2_listed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF2_listed [ ['date', 'time'] + is_col_temp + ['feel_temp', 'response_duration']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF2_listed.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M6EetnpBqZO8"
   },
   "source": [
    "# Reviewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xgEIamPsqZO8"
   },
   "outputs": [],
   "source": [
    "DF2_listed.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZuWFvSDOkNT3"
   },
   "outputs": [],
   "source": [
    "DF2_listed.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nKyhSnDNqZO8"
   },
   "outputs": [],
   "source": [
    "#testing  = ((DF2['feel_air'] + DF2['feel_temp']+DF2['feel_bright']+DF2['feel_health'] +DF2['feel_noise']))\n",
    "#testing2 = ((DF2_listed['feel_air'] + DF2_listed['feel_temp']+DF2_listed['feel_bright']+DF2_listed['feel_health'] +DF2_listed['feel_noise']))\n",
    "#\n",
    "print ('all response        :', DF2[time_name].count() )\n",
    "print ('clean response      :', DF2_listed[time_name].count())\n",
    "print ('unanswered response : ', DF2[time_name].count() - DF2_listed[time_name].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lyiagmu8qZO9"
   },
   "outputs": [],
   "source": [
    "DF3 = DF2_listed\n",
    "DF3['datetime'] = pd.to_datetime(DF3['date'] + ' ' + DF3['time'])\n",
    "DF3[response_counting] = 1\n",
    "DF3.insert(8, response_counting, DF3.pop(response_counting))\n",
    "DF3_1m= DF3.set_index('datetime').resample('1min').sum().round(1)\n",
    "DF3_15m= DF3.set_index('datetime').resample('15min').sum().round(1)\n",
    "DF3_20m= DF3.set_index('datetime').resample('15min').sum().round(1)\n",
    "DF3_30m= DF3.set_index('datetime').resample('30min').sum().round(1)\n",
    "DF3_H= DF3.set_index('datetime').resample('H').sum().round(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U1AVq240qZO9"
   },
   "outputs": [],
   "source": [
    "DF3_3H_ave= DF3.set_index('datetime').resample('3H').mean().round(2)\n",
    "DF3_3H_ave['responses'] = DF3.loc[:,['responses', 'datetime']].set_index('datetime').resample('3H').sum().round(2)\n",
    "DF3_3H_ave = DF3_3H_ave[(DF3_3H_ave[response_counting] > min)]\n",
    "DF3_3H_ave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hV1nDMVlqZO9"
   },
   "outputs": [],
   "source": [
    "DF3_D_ave= DF3.set_index('datetime').resample('D').mean().round(2)\n",
    "DF3_D_ave['responses'] = DF3.loc[:,['responses', 'datetime']].set_index('datetime').resample('D').sum().round(2)\n",
    "DF3_D_ave = DF3_D_ave[(DF3_D_ave[response_counting] > min)]\n",
    "DF3_D_ave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lTAo0kr-qZO9"
   },
   "outputs": [],
   "source": [
    "def description(in_df):\n",
    "    xf = in_df\n",
    "    xf = xf.reset_index()\n",
    "    datechange = pd.to_datetime(xf['datetime'])\n",
    "    xf['date']  = datechange.dt.strftime('%Y-%m-%d')\n",
    "    xf['time']  = datechange.dt.strftime('%H:%M')\n",
    "    xf['hour']  = datechange.dt.hour\n",
    "    daily_check = pd.pivot_table(xf, values=response_counting, index= 'date',aggfunc=np.sum)\n",
    "    #daily_check.columns = [in_df.dtypes]\n",
    "    return daily_check\n",
    "    #xf.columns = xf.info\n",
    "description(DF3_20m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OejGqlfbqZO9"
   },
   "outputs": [],
   "source": [
    "def description(in_df):\n",
    "    xf = in_df\n",
    "    xf = xf.reset_index()\n",
    "    datechange = pd.to_datetime(xf['datetime'])\n",
    "    xf['date']  = datechange.dt.strftime('%Y-%m-%d')\n",
    "    xf['time']  = datechange.dt.strftime('%H:%M')\n",
    "    xf['hour']  = datechange.dt.hour\n",
    "    daily_check = pd.pivot_table(xf, values=response_counting, index= 'time',aggfunc=np.sum)\n",
    "    #daily_check.columns = [in_df.dtypes]\n",
    "    return daily_check\n",
    "    #xf.columns = xf.info\n",
    "description(DF3_H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dd3sSa5fqZO9"
   },
   "outputs": [],
   "source": [
    "DF2 = DF1_new[DF1_new['title']==is_data_class_name].reset_index(drop=True)\n",
    "\n",
    "DF2 [school_col_name]  = school_name\n",
    "DF2 [room_col_name]    = class_dir\n",
    "DF2 [manuf_col_name]   = manuf_id\n",
    "DF2 [instr_col_name]   = instr_id\n",
    "DF2 [serial_col_name]  = serial_id\n",
    "\n",
    "cols_to_move = [school_col_name, room_col_name,'date', 'time', manuf_col_name, instr_col_name, serial_col_name, 'sessionid']\n",
    "DF2         = DF2[ cols_to_move + [ col for col in DF2.columns if col not in cols_to_move ] ].drop([ 'title'], axis=1)\n",
    "#DF2['time'].unique()\n",
    "\n",
    "#filtering rows data regarding to desired specific time. We neglect data if there is a student did not answer anything. for example, from 808 responses, become 757 responses.\n",
    "min = 0\n",
    "\n",
    "#we filterize table with new name of DataFrame, and use specific date and time intervals like above. index has been reset as well.\n",
    "#his tends to eliminate \"Lazy students\" who dont answers all main questions at once. they were considered as outliers.\n",
    "DF2_listed = DF2[(DF2['feel_air'] > min) | (DF2['feel_temp']> min) | (DF2['feel_bright']> min) | (DF2['feel_health'] > min) | (DF2['feel_noise'] > min)].reset_index(level=0, drop=True)\n",
    "\n",
    "#activate this command if we want to select specified date / today's date\n",
    "#DF2_listed = DF2_listed[DF2_listed['date']==spec_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M8eOkt51qZO9"
   },
   "outputs": [],
   "source": [
    "#put spesific Directory and File Name.\n",
    "name_time =DF2_listed['time'].iloc[0]\n",
    "name_date =DF2_listed['date'].iloc[0]\n",
    "directory_path = export_file_directory +class_dir+'/'\n",
    "filename = school_name+'_'+class_dir+ '_'+ instr_id + '_'+serial_id +'_'+name_date +'_'+ name_time + '.csv'\n",
    "\n",
    "# save dataframe (accumulative format) to CSV file in specified directory\n",
    "DF2_listed.to_csv(directory_path + filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bE2KodYHbsjZ"
   },
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "executionInfo": {
     "elapsed": 316,
     "status": "ok",
     "timestamp": 1695051537401,
     "user": {
      "displayName": "Azimil Alam",
      "userId": "11823504813412490778"
     },
     "user_tz": -120
    },
    "id": "C-cMuEpQdZ-M",
    "outputId": "9824663a-08b3-4000-b741-0d542d1393c2"
   },
   "outputs": [],
   "source": [
    "root_folder = export_file_directory\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Walk through the root folder and its sub-folders\n",
    "for foldername, subfolders, filenames in os.walk(root_folder):\n",
    "    for filename in filenames:\n",
    "        # Check if the file is a CSV file\n",
    "        if filename.endswith('.csv'):\n",
    "            # Construct the full path to the CSV file\n",
    "            file_path = os.path.join(foldername, filename)\n",
    "\n",
    "            # Read the CSV file into a DataFrame and append it to the list\n",
    "            df = pd.read_csv(file_path)\n",
    "            dataframes.append(df)\n",
    "comparing = pd.concat(dataframes)\n",
    "\n",
    "comparing = comparing.iloc[:,8:]\n",
    "comparing.iloc[:,:5] = comparing.iloc[:,:5]-4\n",
    "comparing.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 245,
     "status": "ok",
     "timestamp": 1695051095362,
     "user": {
      "displayName": "Azimil Alam",
      "userId": "11823504813412490778"
     },
     "user_tz": -120
    },
    "id": "JyOauDMm4ROh",
    "outputId": "76cedea2-71d6-4451-d079-b984590eb4e1"
   },
   "outputs": [],
   "source": [
    "print(root_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 240,
     "status": "ok",
     "timestamp": 1695051096600,
     "user": {
      "displayName": "Azimil Alam",
      "userId": "11823504813412490778"
     },
     "user_tz": -120
    },
    "id": "ezImjAxzdiJv",
    "outputId": "585c67fc-1541-47d8-9d51-369c42073ec2"
   },
   "outputs": [],
   "source": [
    "comparing.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "executionInfo": {
     "elapsed": 311,
     "status": "ok",
     "timestamp": 1695051103318,
     "user": {
      "displayName": "Azimil Alam",
      "userId": "11823504813412490778"
     },
     "user_tz": -120
    },
    "id": "aUAWSPOX-Pt5",
    "outputId": "cc23ebd3-46af-4819-d0c7-38f543a75c58"
   },
   "outputs": [],
   "source": [
    "comparing.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1852,
     "status": "ok",
     "timestamp": 1695051542219,
     "user": {
      "displayName": "Azimil Alam",
      "userId": "11823504813412490778"
     },
     "user_tz": -120
    },
    "id": "RaBzDxiZduXY",
    "outputId": "ca71c4e3-6813-4361-dc11-9c7b7c002c06"
   },
   "outputs": [],
   "source": [
    "#Heatmap Correlation\n",
    "#call the DataFrame\n",
    "#corr = comparing.corr().round(2)\n",
    "#corr = comparing.drop(['Unnamed: 0'], axis=1).fillna(0).corr() #.round(2)   #\n",
    "corr = comparing.fillna(0).corr() #.round(2)   #\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(22, 12))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220,10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask,cmap=\"RdYlGn\", vmin=-0.75, vmax=0.75, center=0, cbar=True, annot =True,\n",
    "            square=True, linewidths=.5, annot_kws={\"size\": 10})\n",
    "plt.xticks(rotation=90, fontsize=12)\n",
    "\n",
    "plt.title(school_name +'- Niluapp'+ ' : Correlation', fontsize=15)\n",
    "plt.yticks(fontsize=12,rotation=0 )"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOnnn9Z5ijLxzbDLyE460FM",
   "collapsed_sections": [
    "5k8zB7YMWQH2",
    "cF0Myfy5sycW",
    "TQKs9N6xs5Hv",
    "1KsyONrnr9G7",
    "Kl_-W66KsCFt",
    "ILew736csFgk",
    "MB6m2Me8tId2",
    "TSZFqihVNpKH",
    "oBdYYSGtTKof",
    "CWx1sA42TKog",
    "j8W9NhFfTKoh",
    "kfOZkT6-TKoi",
    "C24yDYhCTKoi",
    "SEG9stCaTKoj",
    "_ZSrcCz8pNiW",
    "J6GQZOtFpNiW",
    "o1m83FKhpNiY",
    "HlHlfTnypNiY",
    "pyxjzoHfpNiZ",
    "snhG2wEnqZO5",
    "xouUnGTSqZO6",
    "600OeP3EqZO7",
    "0r80TIdNqZO7",
    "M6EetnpBqZO8"
   ],
   "mount_file_id": "1N9XALUUyaBJfvaqpRRBKcCedrLe2i5gn",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "coderefinery",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
