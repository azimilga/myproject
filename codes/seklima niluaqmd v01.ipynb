{"cells":[{"cell_type":"markdown","metadata":{"id":"y-gvYTR0y3NQ"},"source":["**WRITER'S IDENTITY**\n","- AZIMIL GANI ALAM\n","- Ph.D Student\n","- Dept. Energy & Process Tech - NTNU\n","\n","\n","**NOTE :**\n","- This Python File runs in GoogleColab\n","- This work uses\n","  - **Weather Data Record by WWW.SEKLIMA.NO**\n","  - **Outdoor Data Record by NILU Air Quality Monitoring Data**\n","- we want to filterize data results from CSV models become process-ready for Machine Learning process"]},{"cell_type":"markdown","metadata":{"id":"dOrE8iE7ZNN1"},"source":["**RULES**\n","1. Run Library Import\n","2. Select Notebook platform by run one of those commands.\n","3. Expand Schools Tab\n"," - Run Identity and Data Caller\n"," - Expand Classrooms\n"," - Run one of Klasserom- XXX\n"," - Run Processor. if done, select again one of Klasserom and run again the processor. it is cyclic process\n","\n","to check the data cleaning result, run 'Data Preparation'.\n"]},{"cell_type":"markdown","metadata":{"id":"obgZUNYWOz3R"},"source":["# Libraries Import"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":1295,"status":"ok","timestamp":1696500528630,"user":{"displayName":"Azimil Alam","userId":"11823504813412490778"},"user_tz":-120},"id":"0L3H4n-ROuzb"},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy as np\n","import os\n","from datetime import datetime, timedelta\n","import pytz"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["#Folder naming directory\n","platform_directory = 'C:/Users/azimilga'\n","folder_raw     = 'data-raw'\n","folder_ready   = 'data-ready'\n","folder_year    = '2024'\n","folder_project = 'project'"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1696500528630,"user":{"displayName":"Azimil Alam","userId":"11823504813412490778"},"user_tz":-120},"id":"fmJz6DACeXr9"},"outputs":[],"source":["school_col_name   = 'school_id'\n","room_col_name     = 'room_id'\n","date_name         = 'date'\n","time_name         = 'time'\n","manuf_col_name    = 'manuf_id'\n","instr_col_name    = 'instr_id'\n","serial_col_name   = 'serial_id'\n","temp_set_name     = 'temp_o'\n","rel_hum_name      = 'rh_o'\n","sun_rad_name      = 'sun_o'\n","winds_name        =  'winds_o'\n","percipitation_name= 'rain_o'\n","pm25_name         = 'pm2.5_o'\n","pm10_name         = 'pm10_o'\n","pressure_name     = 'press_o'\n","gas_nox_name      = 'nox_o'\n","gas_no_name      = 'no_o'\n","gas_no2_name      = 'no2_o'\n","\n","school_col_name   = 'school_id'\n","room_col_name     = 'room_id'\n","date_name         = 'date'\n","time_name         = 'time'\n","manuf_col_name    = 'manuf_id'\n","instr_col_name    = 'instr_id'\n","serial_col_name   = 'serial_id'\n","\n","#identify a datetime name : wont be displayed. just coding purpose\n","datetime_name = 'datetime'\n","\n","#filtering rows data regarding to desired specific time\n","start_time =  '00:00:00'\n","end_time   =  '23:59:59'\n","start_date =  '2024-01-01'\n","end_date   =  '2024-05-30'\n","date_format_show =  '%Y-%m-%d'\n","time_format_show =  '%H:%M'\n","spec_date = pd.to_datetime('today').strftime(date_format_show)\n","name_date = pd.to_datetime('today').strftime(\"%y%m%d\")\n","\n","# Define the timezones (UTC and Europe/Oslo)\n","utc_timezone = pytz.timezone('UTC')\n","oslo_timezone = pytz.timezone('Europe/Oslo')"]},{"cell_type":"markdown","metadata":{"id":"btfS2eEBG8ac"},"source":["# Volda"]},{"cell_type":"markdown","metadata":{"id":"9F3Zqe20opXy"},"source":["## Bratteberg"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"zGs7pEkRHapb"},"outputs":[],"source":["school_name = 'bratteberg'\n","manuf_id    = 'seklima'\n","instr_id    = 'volda lufthamn'\n","serial_id   = 'SN59680'\n","input_file_directory    = platform_directory + '/' + folder_project + '/' + folder_raw   + '/' + folder_year + '/' + school_name + '/' + manuf_id + '/'\n","export_file_directory   = platform_directory + '/' + folder_project + '/' + folder_ready + '/' + folder_year + '/' + school_name + '/' + manuf_id + '/'\n","\n","weather_column_array = [  instr_col_name,serial_col_name, datetime_name, pressure_name, temp_set_name,rel_hum_name, winds_name,  percipitation_name]\n"]},{"cell_type":"markdown","metadata":{"id":"IgM-WViwovMm"},"source":["## Øyra"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"7r1oLsVgoxDI"},"outputs":[],"source":["school_name = 'øyra'\n","manuf_id    = 'seklima'\n","instr_id    = 'volda lufthamn'\n","serial_id   = 'SN59680'\n","input_file_directory  = platform_directory + '/' + folder_project + '/' + folder_raw + '/' + folder_year + '/' + school_name + '/' + manuf_id + '/'\n","export_file_directory   = platform_directory + '/'+ folder_project + '/' + folder_ready + '/' + folder_year + '/' + school_name + '/' + manuf_id + '/'\n","\n","weather_column_array = [  instr_col_name,serial_col_name, datetime_name, pressure_name, temp_set_name,rel_hum_name, winds_name,  percipitation_name]"]},{"cell_type":"markdown","metadata":{},"source":["## Processing"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["folder_path1 = input_file_directory # replace with the folder path\n","csv_files1 = [f for f in os.listdir(folder_path1) if f.endswith('.xlsx')] # get list of csv files\n","dfs1 = [] # list to store dataframes\n","\n","for file in csv_files1:\n","    file_path = os.path.join(folder_path1, file) # get full path of csv file\n","    df = pd.read_excel(file_path  ) # read csv file into a dataframe delimiter=';', \n","    dfs1.append(df) # append dataframe to list\n","\n","# concatenate dataframes in the list into a single dataframe\n","DF1 = pd.concat(dfs1, ignore_index=True).iloc[:-1]\n","DF1.columns = weather_column_array\n","DF1[datetime_name] = pd.to_datetime((DF1[datetime_name]), format= '%d.%m.%Y %H:%M')\n","timezone = DF1[datetime_name].dt.tz_localize(oslo_timezone,  ambiguous='NaT', nonexistent='shift_forward').dt.tz_convert(utc_timezone)\n","DF1[datetime_name] =  timezone.dt.tz_localize(None)\n","\n","#DF1.set_index(datetime_name, inplace=True)\n","DF1.iloc[:,3:] = DF1.iloc[:,3:].replace('-', regex=True).astype(float).interpolate(method='linear')  #to handle minus string values. tell pandas to read it as minus value, not a string typing\n","\n","DF1[instr_col_name] = instr_id  \n","DF1[school_col_name] = school_name\n","DF1[serial_col_name] = serial_id   \n","DF1[manuf_col_name] = manuf_id\n","DF1[date_name] = DF1[datetime_name ].dt.strftime(date_format_show)\n","DF1[time_name] = DF1[datetime_name ].dt.strftime(time_format_show)\n","\n","#we move columns named 'Date' and 'Time' to the front side\n","cols_to_move = [school_col_name, date_name, time_name, manuf_col_name, instr_col_name, serial_col_name ]\n","DF1         = DF1[ cols_to_move + [ col for col in DF1.columns if col not in cols_to_move ] ].drop([datetime_name], axis=1).dropna()\n","\n","#put spesific Directory and File Name.\n","name_time = datetime.strptime((DF1[time_name].iloc[0]),'%H:%M').strftime('%H%M')\n","name_date = datetime.strptime((DF1[date_name].iloc[0]),'%Y-%m-%d').strftime('%Y%m%d')\n","\n","directory_path = export_file_directory+'/'\n","filename = school_name+ '_'+ instr_id + '_'+serial_id +'_'+name_date +'_'+ name_time + '.csv'\n","\n","# save dataframe (accumulative format) to CSV file in specified directory\n","DF1.to_csv(directory_path + filename, index= False)"]},{"cell_type":"markdown","metadata":{"id":"UrKCtaesFqy1"},"source":["# Oslo"]},{"cell_type":"markdown","metadata":{"id":"sqN1TrrYN3da"},"source":["## Brannfjell"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["school_name = 'brannfjell'\n","manuf_id    = 'seklima'\n","instr_id = 'Oslo - Blindern'\n","instr_id2   = ' & nilu manglerud'\n","serial_id = 'SN18700'\n","input_file_directory  = platform_directory + '/' + folder_project + '/' + folder_raw + '/' + folder_year + '/' + school_name + '/' + manuf_id + '/'\n","\n","weather_column_array = [ instr_col_name,serial_col_name, datetime_name, temp_set_name, rel_hum_name, winds_name, percipitation_name, pressure_name, sun_rad_name]\n","pollution_column_array = [datetime_name,pm10_name,pm25_name]"]},{"cell_type":"markdown","metadata":{"id":"YHLciD7ZNRyz"},"source":["## KubenVGS"]},{"cell_type":"code","execution_count":125,"metadata":{},"outputs":[],"source":["school_name = 'kubenVGS'\n","manuf_id    = 'seklima'\n","instr_id = 'Oslo - Blindern'\n","instr_id2   = ' & nilu alnabru'\n","serial_id = 'SN18700'\n","input_file_directory  = platform_directory + '/' + folder_project + '/' + folder_raw + '/' + folder_year + '/' + school_name + '/' + manuf_id + '/'\n","\n","weather_column_array = [ instr_col_name,serial_col_name, datetime_name, temp_set_name, rel_hum_name, winds_name, percipitation_name, pressure_name, sun_rad_name]\n","pollution_column_array = [datetime_name,pm10_name,pm25_name, gas_nox_name, gas_no2_name, gas_no_name]"]},{"cell_type":"markdown","metadata":{},"source":["## KubenYA"]},{"cell_type":"code","execution_count":59,"metadata":{},"outputs":[],"source":["school_name = 'kubenFS'\n","manuf_id    = 'seklima'\n","instr_id = 'Oslo - Blindern'\n","instr_id2   = ' & nilu alnabru'\n","serial_id = 'SN18700'\n","input_file_directory  = platform_directory + '/' + folder_project + '/' + folder_raw + '/' + folder_year + '/' + school_name + '/' + manuf_id + '/'\n","\n","weather_column_array = [ instr_col_name,serial_col_name, datetime_name, temp_set_name, rel_hum_name, winds_name, percipitation_name, pressure_name, sun_rad_name]\n","pollution_column_array = [datetime_name,pm10_name,pm25_name]"]},{"cell_type":"markdown","metadata":{},"source":["## Processing"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\azimilga\\AppData\\Local\\Temp\\ipykernel_23892\\1178769506.py:23: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n","  DF1.iloc[:,2:] = DF1.iloc[:,2:].replace('-', regex=True).astype(float).interpolate(method='linear')  #to handle minus string values. tell pandas to read it as minus value, not a string typing\n"]}],"source":["folder_path1 = input_file_directory # replace with the folder path\n","csv_files1 = [f for f in os.listdir(folder_path1) if f.endswith('.xlsx')] # get list of csv files\n","dfs1 = [] # list to store dataframes\n","\n","for file in csv_files1:\n","    file_path = os.path.join(folder_path1, file) # get full path of csv file\n","    df = pd.read_excel(file_path  ) # read csv file into a dataframe delimiter=';', \n","    dfs1.append(df) # append dataframe to list\n","\n","# concatenate dataframes in the list into a single dataframe\n","DF1 = pd.concat(dfs1, ignore_index=True).iloc[:-1]\n","\n","DF1.columns = weather_column_array\n","\n","DF1[datetime_name] = pd.to_datetime((DF1[datetime_name]), format= '%d.%m.%Y %H:%M')\n","timezone = DF1[datetime_name].dt.tz_localize(oslo_timezone,  ambiguous='NaT', nonexistent='shift_forward').dt.tz_convert(utc_timezone)\n","DF1[datetime_name] =  timezone.dt.tz_localize(None)\n","\n","#special for Oslo\n","DF1.set_index(datetime_name, inplace=True)\n","# DFsolar= DF1[DF1[serial_col_name]!=serial_id][sun_rad_name].iloc[2:].reset_index().set_index(datetime_name).applymap(lambda x: max(0, x))\n","# DF1 =   DF1[DF1[serial_col_name]==serial_id].drop(sun_rad_name, axis=1).join(DFsolar, how='outer').dropna(axis=0).iloc[1:]\n","DF1.iloc[:,2:] = DF1.iloc[:,2:].replace('-', regex=True).astype(float).interpolate(method='linear')  #to handle minus string values. tell pandas to read it as minus value, not a string typing\n","DF1#.mean() #.info()\n","\n","\n","#importing data from NILU HISTORIKK DATA\n","manuf_id2    = 'niluaqmd'\n","input_file_directory2  = platform_directory + '/' + folder_project + '/' + folder_raw + '/' + folder_year + '/' + school_name + '/' + manuf_id2 + '/'\n","folder_path2 = input_file_directory2 # replace with the folder path\n","csv_files2 = [f for f in os.listdir(folder_path2) if f.endswith('.csv')] # get list of csv files\n","dfs1 = [] # list to store dataframes\n","\n","for file in csv_files2:\n","    file_path = os.path.join(folder_path2, file) # get full path of csv file\n","    df = pd.read_csv(file_path,delimiter=\";\", header=3)#.iloc[5,:] # read csv file into a dataframe\n","    dfs1.append(df) # append dataframe to list\n","\n","# concatenate dataframes in the list into a single dataframe\n","DF2 = pd.concat(dfs1, ignore_index=True)\n","DF2 = DF2.drop(columns=DF2.filter(regex=f'Dekning', axis=1).columns, axis=1)\n","DF2.columns= pollution_column_array\n","\n","DF2[datetime_name] = pd.to_datetime((DF2[datetime_name]), format= '%d.%m.%Y %H:%M')\n","timezone = DF2[datetime_name].dt.tz_localize(oslo_timezone,  ambiguous='NaT', nonexistent='shift_forward').dt.tz_convert(utc_timezone)\n","DF2[datetime_name] =  timezone.dt.tz_localize(None)\n","\n","DF2 = DF2.set_index(datetime_name)\n","DF2 = DF2.astype(str).replace(',', '.', regex=True).astype(float)#.applymap(lambda x: max(0, x))#.astype(float)\n","DF2 = DF2.interpolate(method='linear').applymap(lambda x: max(0, x))\n","\n","#JOINING SEKLIMA AND NILU HISTORIKK DATA\n","DF3 = DF1.join(DF2, how='outer').dropna()\n","DF3 = DF3.drop([instr_col_name,serial_col_name],axis=1).resample('1H').mean().reset_index()\n","\n","DF3[instr_col_name] = instr_id  + instr_id2 \n","DF3[school_col_name] = school_name\n","DF3[serial_col_name] = serial_id   \n","DF3[manuf_col_name] = manuf_id + '+' + manuf_id2\n","DF3[date_name] = DF3[datetime_name ].dt.strftime(date_format_show)\n","DF3[time_name] = DF3[datetime_name ].dt.strftime(time_format_show)\n","DF3\n","\n","#we move columns named 'Date' and 'Time' to the front side\n","cols_to_move = [school_col_name, date_name, time_name, manuf_col_name, instr_col_name, serial_col_name  ,   temp_set_name, rel_hum_name, winds_name  ]\n","DF3         = DF3[ cols_to_move + [ col for col in DF3.columns if col not in cols_to_move ] ].drop([datetime_name], axis=1).dropna()\n","\n","DF3.iloc[:,6:]=DF3.iloc[:,6:].astype(float)#.describe()\n","\n","#put spesific Directory and File Name.\n","name_time = datetime.strptime((DF3[time_name].iloc[0]),'%H:%M').strftime('%H%M')\n","name_date = datetime.strptime((DF3[date_name].iloc[0]),'%Y-%m-%d').strftime('%Y%m%d')\n","\n","export_file_directory   = platform_directory + '/'+ folder_project + '/' + folder_ready + '/' + folder_year + '/'  + school_name + '/' + manuf_id + '/'\n","directory_path = export_file_directory+'/'\n","filename = school_name+ '_'+ manuf_id + '_'+serial_id +'_'+name_date +'_'+ name_time + '.csv'\n","\n","# save dataframe (accumulative format) to CSV file in specified directory\n","DF3.to_csv(directory_path + filename, index= False)"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>school_id</th>\n","      <th>date</th>\n","      <th>time</th>\n","      <th>manuf_id</th>\n","      <th>instr_id</th>\n","      <th>serial_id</th>\n","      <th>temp_o</th>\n","      <th>rh_o</th>\n","      <th>winds_o</th>\n","      <th>rain_o</th>\n","      <th>press_o</th>\n","      <th>sun_o</th>\n","      <th>pm10_o</th>\n","      <th>pm2.5_o</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>brannfjell</td>\n","      <td>2024-01-01</td>\n","      <td>00:00</td>\n","      <td>seklima+niluaqmd</td>\n","      <td>Oslo - Blindern &amp; nilu manglerud</td>\n","      <td>SN18700</td>\n","      <td>-3.9</td>\n","      <td>85.0</td>\n","      <td>7.2</td>\n","      <td>0.3</td>\n","      <td>998.7</td>\n","      <td>-0.80</td>\n","      <td>64.24</td>\n","      <td>52.3</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>brannfjell</td>\n","      <td>2024-01-01</td>\n","      <td>01:00</td>\n","      <td>seklima+niluaqmd</td>\n","      <td>Oslo - Blindern &amp; nilu manglerud</td>\n","      <td>SN18700</td>\n","      <td>-3.9</td>\n","      <td>85.0</td>\n","      <td>7.5</td>\n","      <td>0.4</td>\n","      <td>998.7</td>\n","      <td>-0.85</td>\n","      <td>7.81</td>\n","      <td>5.9</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>brannfjell</td>\n","      <td>2024-01-01</td>\n","      <td>02:00</td>\n","      <td>seklima+niluaqmd</td>\n","      <td>Oslo - Blindern &amp; nilu manglerud</td>\n","      <td>SN18700</td>\n","      <td>-4.1</td>\n","      <td>86.0</td>\n","      <td>6.7</td>\n","      <td>0.4</td>\n","      <td>998.3</td>\n","      <td>-0.87</td>\n","      <td>3.19</td>\n","      <td>3.3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>brannfjell</td>\n","      <td>2024-01-01</td>\n","      <td>03:00</td>\n","      <td>seklima+niluaqmd</td>\n","      <td>Oslo - Blindern &amp; nilu manglerud</td>\n","      <td>SN18700</td>\n","      <td>-4.4</td>\n","      <td>86.0</td>\n","      <td>8.4</td>\n","      <td>0.4</td>\n","      <td>998.0</td>\n","      <td>-0.94</td>\n","      <td>3.85</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>brannfjell</td>\n","      <td>2024-01-01</td>\n","      <td>04:00</td>\n","      <td>seklima+niluaqmd</td>\n","      <td>Oslo - Blindern &amp; nilu manglerud</td>\n","      <td>SN18700</td>\n","      <td>-4.6</td>\n","      <td>83.0</td>\n","      <td>9.1</td>\n","      <td>0.4</td>\n","      <td>998.0</td>\n","      <td>-0.93</td>\n","      <td>2.42</td>\n","      <td>3.8</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2898</th>\n","      <td>brannfjell</td>\n","      <td>2024-04-30</td>\n","      <td>18:00</td>\n","      <td>seklima+niluaqmd</td>\n","      <td>Oslo - Blindern &amp; nilu manglerud</td>\n","      <td>SN18700</td>\n","      <td>14.9</td>\n","      <td>60.0</td>\n","      <td>2.2</td>\n","      <td>0.0</td>\n","      <td>1014.4</td>\n","      <td>66.58</td>\n","      <td>13.09</td>\n","      <td>6.6</td>\n","    </tr>\n","    <tr>\n","      <th>2899</th>\n","      <td>brannfjell</td>\n","      <td>2024-04-30</td>\n","      <td>19:00</td>\n","      <td>seklima+niluaqmd</td>\n","      <td>Oslo - Blindern &amp; nilu manglerud</td>\n","      <td>SN18700</td>\n","      <td>13.8</td>\n","      <td>63.0</td>\n","      <td>1.9</td>\n","      <td>0.0</td>\n","      <td>1014.8</td>\n","      <td>22.39</td>\n","      <td>13.09</td>\n","      <td>6.6</td>\n","    </tr>\n","    <tr>\n","      <th>2900</th>\n","      <td>brannfjell</td>\n","      <td>2024-04-30</td>\n","      <td>20:00</td>\n","      <td>seklima+niluaqmd</td>\n","      <td>Oslo - Blindern &amp; nilu manglerud</td>\n","      <td>SN18700</td>\n","      <td>13.0</td>\n","      <td>59.0</td>\n","      <td>2.3</td>\n","      <td>0.0</td>\n","      <td>1014.6</td>\n","      <td>-0.40</td>\n","      <td>13.09</td>\n","      <td>6.6</td>\n","    </tr>\n","    <tr>\n","      <th>2901</th>\n","      <td>brannfjell</td>\n","      <td>2024-04-30</td>\n","      <td>21:00</td>\n","      <td>seklima+niluaqmd</td>\n","      <td>Oslo - Blindern &amp; nilu manglerud</td>\n","      <td>SN18700</td>\n","      <td>12.2</td>\n","      <td>58.0</td>\n","      <td>3.2</td>\n","      <td>0.0</td>\n","      <td>1014.4</td>\n","      <td>-1.71</td>\n","      <td>13.09</td>\n","      <td>6.6</td>\n","    </tr>\n","    <tr>\n","      <th>2902</th>\n","      <td>brannfjell</td>\n","      <td>2024-04-30</td>\n","      <td>22:00</td>\n","      <td>seklima+niluaqmd</td>\n","      <td>Oslo - Blindern &amp; nilu manglerud</td>\n","      <td>SN18700</td>\n","      <td>12.2</td>\n","      <td>59.0</td>\n","      <td>4.7</td>\n","      <td>0.0</td>\n","      <td>1014.5</td>\n","      <td>-1.77</td>\n","      <td>13.09</td>\n","      <td>6.6</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2903 rows × 14 columns</p>\n","</div>"],"text/plain":["       school_id        date   time          manuf_id  \\\n","0     brannfjell  2024-01-01  00:00  seklima+niluaqmd   \n","1     brannfjell  2024-01-01  01:00  seklima+niluaqmd   \n","2     brannfjell  2024-01-01  02:00  seklima+niluaqmd   \n","3     brannfjell  2024-01-01  03:00  seklima+niluaqmd   \n","4     brannfjell  2024-01-01  04:00  seklima+niluaqmd   \n","...          ...         ...    ...               ...   \n","2898  brannfjell  2024-04-30  18:00  seklima+niluaqmd   \n","2899  brannfjell  2024-04-30  19:00  seklima+niluaqmd   \n","2900  brannfjell  2024-04-30  20:00  seklima+niluaqmd   \n","2901  brannfjell  2024-04-30  21:00  seklima+niluaqmd   \n","2902  brannfjell  2024-04-30  22:00  seklima+niluaqmd   \n","\n","                              instr_id serial_id  temp_o  rh_o  winds_o  \\\n","0     Oslo - Blindern & nilu manglerud   SN18700    -3.9  85.0      7.2   \n","1     Oslo - Blindern & nilu manglerud   SN18700    -3.9  85.0      7.5   \n","2     Oslo - Blindern & nilu manglerud   SN18700    -4.1  86.0      6.7   \n","3     Oslo - Blindern & nilu manglerud   SN18700    -4.4  86.0      8.4   \n","4     Oslo - Blindern & nilu manglerud   SN18700    -4.6  83.0      9.1   \n","...                                ...       ...     ...   ...      ...   \n","2898  Oslo - Blindern & nilu manglerud   SN18700    14.9  60.0      2.2   \n","2899  Oslo - Blindern & nilu manglerud   SN18700    13.8  63.0      1.9   \n","2900  Oslo - Blindern & nilu manglerud   SN18700    13.0  59.0      2.3   \n","2901  Oslo - Blindern & nilu manglerud   SN18700    12.2  58.0      3.2   \n","2902  Oslo - Blindern & nilu manglerud   SN18700    12.2  59.0      4.7   \n","\n","      rain_o  press_o  sun_o  pm10_o  pm2.5_o  \n","0        0.3    998.7  -0.80   64.24     52.3  \n","1        0.4    998.7  -0.85    7.81      5.9  \n","2        0.4    998.3  -0.87    3.19      3.3  \n","3        0.4    998.0  -0.94    3.85      3.0  \n","4        0.4    998.0  -0.93    2.42      3.8  \n","...      ...      ...    ...     ...      ...  \n","2898     0.0   1014.4  66.58   13.09      6.6  \n","2899     0.0   1014.8  22.39   13.09      6.6  \n","2900     0.0   1014.6  -0.40   13.09      6.6  \n","2901     0.0   1014.4  -1.71   13.09      6.6  \n","2902     0.0   1014.5  -1.77   13.09      6.6  \n","\n","[2903 rows x 14 columns]"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["DF3"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOYJ07KTLjWEl/tAQGB/o2C","mount_file_id":"1P5IOtxAkOr2boEMjAxddpY9-z28aEu5P","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":0}
